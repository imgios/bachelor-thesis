\phantomsection
%\addcontentsline{toc}{chapter}{Dipendenze Funzionali per Big Data e Dati Multimediali}
\chapter{Dipendenze Funzionali per Big Data}
\label{cap3:fd}
\markboth{Dipendenze Funzionali per Big Data}{}
% [titolo ridotto se non ci dovesse stare] {titolo completo}
In questo capitolo verr\`{a} introdotto il concetto di \acrlong{rfd} per big data. Sebbene tali database possano essere organizzati in modo pi\'{u} adeguato mediante modelli di dati flessibili, come ad esempio NoSQL, nel seguito faremo riferimento al modello di dati relazionale, per motivi di semplicit\`{a}, rigore delle definizioni e senza perdita di generalit\`{a}.\par
Di seguito l'acronimo \acrshort{fd} verr\`{a} utilizzato per indicare le \acrlong{fds} e \acrshort{rfd} verr\`{a} utilizzato per indicare le \acrlong{rfds}.

\section{Concetti Preliminari} %\label{1sec:scopo}
Si consideri uno schema di database relazionale $\mathcal{R}$ definito su un insieme di attributi $attr(\mathcal{R})$, derivato come unione degli attributi degli schemi di relazione che compongono $\mathcal{R}$. Per un'istanza $r$ in $\mathcal{R}$, un attributo $A \in attr(\mathcal{R})$ ed una tupla $t \in r$, utilizziamo $t[A]$ per denotare la proiezione di $t$ su $A$; allo stesso modo, per un insieme $X$ di attributi in $attr(\mathcal{R})$, $t[X]$ denota la prezione di $t$ su $X$. Una \acrshort{fd} su $\mathcal{R}$ \`{e} una dichiarazione $X \rightarrow Y$ ($X$ implica $Y$), con $X, Y \subseteq attr(\mathcal{R})$, tale che, data un'istanza $r$ di $\mathcal{R}$, $X \rightarrow Y$ \`{e} soddisfatta in $r$ se e soltanto se per ogni coppia di tuple $(t_1, t_2)$ in $r$, tutte le volte che $t_1[X]=t_2[X]$, allora $t_1[Y]=t_2[Y]$.\par
Dalla definizione precedente possiamo notare come le proiezioni di due tuple, su un insieme di attributi, vengano confrontate mediante una funzione di uguaglianza. Ci\`{o} non \`{e} possibile in un contesto di big data o dati multimediali. Ad esempio, nel contesto dei dati multimediali \`{e} inconcepibile confrontare immagini o suoni mediante paradigmi di esatta corrispondenza. Piuttosto, potrebbero essere confrontate mediante funzioni di somiglianza che per le immagini potrebbero basarsi su attributi come colore, texture, forma e cos\`{i} via, mentre per i suoni potrebbero basarsi su volume, tono, larghezza di banda e cos\`{i} via. Considerazioni simili possono essere effettuate per i big data, nel caso di dati alfanumerici potrebbero essere necessari dei confronti approssimati a causa dei differenti formati, errori nei dati, inconsistenze e scale diverse. Inoltre, in ambo i contesti di big data e multimedia, potrebbero esserci dipendenze rilevanti che sono valide solo su un sottoinsieme di dati. Per questa ragione, la definizione di \acrshort{fd} \`{e} stata estesa in diversi modi per considerare i confronti approssimati tra tuple e misure per specificare il sottoinsieme di dati su cui una data dipendenza si applica. A tal fine, molte nuove definizioni fanno affidamento ai valori soglia per valutare la somiglianza nei confronti tra coppie di tuple o per specificare il numero minimo di tuple a cui una dipendenza deve applicarsi per essere valida.

\section{Dipendenze Funzionali Rilassate}
\theoremstyle{definition}
\newtheorem{rfddef}{Dipendenze funzionali rilassate}
\begin{rfddef}\label{def:rfd}
Si consideri uno schema di database relazionale $\mathcal{R}$ ed uno schema di relazione $R = (A_1, A_2,\text{\textellipsis}, A_m)$ di $\mathcal{R}$. Una \acrshort{rfd} $\varphi$ su $\mathcal{R}$ \`{e} indicata da
\begin{equation}
    \mathbb{D}_c : X_{\Phi1} \xrightarrow{\Psi\leq\varepsilon} Y_{\Phi_2}
\end{equation}
dove:
\begin{itemize}
    \item $\mathbb{D}_c=\{t \in dom(R) | \bigwedge\limits_{\imath=1}^{m}c_{\imath}(t[A_{\imath}])\}$
    \\con $c=(c_1,\text{\textellipsis},c_m)$ ed ogni $c_\imath$ \`{e} un predicato su $dom(A_\imath)$ che filtra le tuple su cui $\varphi$ si applica;
    \item $X=X_1,\text{\textellipsis},X_h \text{ e } Y=Y_1,\text{\textellipsis},Y_k$, con $X,Y\subseteq attr(R)$ e $X\cap Y=\emptyset$;
    \item $\Phi_1=\bigwedge\limits_{X_\imath \in X}\phi_\imath[X_\imath] \text{ (} \Phi_2=\bigwedge\limits_{Y_\jmath \in Y}\phi_\jmath[Y_\jmath] \text{, analog.)}$, dove $\phi_\imath \text{ (}\phi_\jmath\text{, analog.)}$ \`{e} un vincolo su $X_\imath$ ($Y_\jmath$, analog.) con $\imath=1,\text{\textellipsis},h$ ($\jmath=1,\text{\textellipsis},k$, analog.). Ogni $\phi_\imath$ \`{e} un predicato che coinvolge una funzione di distanza o similitudine, definita sul dominio di $X_\imath$, pi\`{u} uno o pi\`{u} operatori di confronto con soglie associate. Per ogni coppia di tuple $(t_1,t_2)\in\mathbb{D}_c$, il vincolo $\Phi_1$ ($\Phi_2$, analog.) \`{e} vero se la similitudine o la distanza tra $t_1[X_\imath]$ e $t_2[X_\imath]$ ($t_1[Y_\jmath]$ e $t_2[Y_\jmath]$, analog.) soddisfa il vincolo $\phi_\imath$ ($\phi_\jmath$, analog.) $\forall \imath \in [1,h]$ ($\jmath \in [1,k]$, analog.);
    \item $\Psi$ \`{e} una misura di copertura (coverage measure) definita su $\mathbb{D}_c$ che quantifica la quantit\`{a} di tuple che soddisfa o viola $\varphi$. Tra i tipi di misure di copertura pi\`{u} utilizzati vi sono la confidence, la probabilit\`{a} e l'errore g3;
    \item $\varepsilon$ \`{e} una soglia che indica il limite superiore (oppure inferiore nel caso dell'operatore $\geq$) per il risultato delle misure di copertura.
\end{itemize}
\end{rfddef}
Sia $r\subseteq\mathbb{D}_c$ una relazione su $R$, $r$ soddisfa la \acrshort{rfd} $\varphi$, denotato con $r\models\varphi$, se e soltanto se: $\forall t_1,t_2 \in r$, se soddisfa $\Phi_1$, allora soddisfer\`{a} \textit{quasi sempre} anche $\Phi_2$. \textit{Quasi sempre} \`{e} espresso dal vincolo $\Psi\leq\varepsilon$. Un vincolo $\Phi$ \`{e} un predicato che valuta se la distanza o la similitudine tra due valori di un attributo rientra in intervalli predefiniti. Cos\`{i}, un vincolo dipende su una funzione di distanza o similitudine definita sul dominio di un attributo, con uno o pi\`{u} operatori di confronto con valori soglia associati, definendo gli intervalli possibili di valori.\par
Nella letteratura vi sono pi\`{u} di trenta definizioni differenti per le \acrshort{rfds} \cite{rfdsurvey}. Tutte danno origine alla definizione data (\ref{def:rfd}), tranne la definizione di dipendenza di matching \cite{dynamicconstraints}, la quale istanzia la definizione fornita in \cite{rfdsurvey}.
\\I tipi di \acrshort{rfd} pi\`{u} rilevanti sono:
\begin{itemize}
    \item \textit{Dipendenze funzionali approssimate} (AFD) sono \acrshort{fd} che devono essere soddisfatte dalla maggior parte di tuple di una relazione $r$, piuttosto che da tutte \cite{approximateinferencefd}. In altre parole, una AFD consente ad una piccola porzione di tuple di $r$ di violarla. Sono stati proposti diversi approcci per calcolare tale porzione di tuple \cite{approx4fd}, tra cui la misura dell'errore g3 \`{e} il pi\`{u} utilizzato \cite{approximateinferencefd};
    \item \textit{Dipendenze funzionali condizionali} (CFD) usano condizioni per specificare il sottoinsieme ($\mathbb{D}_c$) di tuple su cui una dipendenza si applica \cite{conditionalfd4datacleaning};
    \item \textit{Dipendenze di matching} (MD) furono proposte per l'identificazione degli oggetti, definite in terminit di predicati di similitudine per adattare errori e rappresentazioni differenti in sorgenti di dati non attendibili \cite{dynamicconstraints};
    \item \textit{Dipendenze differenziali} (DD) specificano vincoli sulle differenze tra i valori di attributi invece di utilizzare la corrispondenza esatte delle \acrshort{fds} \cite{differentialdependencies}.
\end{itemize}

\section{Esempi}
Un esempio di \acrshort{rfd} nel contesto multimediale \`{e}:
\\\centerline{$ECG_{(\sigma',\leq0.1)}\rightarrow PULSE_{(\sigma",\leq0.2)}$}
\\dove l'attributo $ECG$ rappresenta l'elettrocardiogramma, mentre $PULSE$ rappresenta il battito cardiaco dei pazienti in un database di ricoveri clinici. La \acrshort{rfd} si basa su una funzione di similitudine delle immagini $\sigma'$ per confrontare gli $ECG$ ed una funzione di somiglianza dei suoni $\sigma"$ per confrontare i battiti cardiaci. Il vincolo impone che per ogni coppia di tuple $t_1$ e $t_2$, tale che $t_1[ECG]$ \`{e} considerato simile a $t_2[ECG]$ entro il valore soglia pari a $0.1$ secondo $\sigma'$, allora $t_1[PULSE]$ \`{e} considerato simile a $t_2[PULSE]$ entro il valore soglia pari a $0.2$ secondo $\sigma"$.\par
Un altro esempio di \acrshort{rfd} su un database di cani \`{e}:
\\\centerline{$BREED_{(\sigma',\leq0.05)}\rightarrow PHOTO_{(\sigma",\leq0.1)}$}
\\dove $BREED$ \`{e} un attributo alfanumerico che memorizza la razza del cane e $PHOTO$ \`{e} un attributo che memorizza la sua immagine. Quindi, date due tuple $t_1$ e $t_2$, se due stringhe $t_1[BREED]$ e $t_2[BREED]$ hanno una distanza minore di $0.05$ secondo una funzione di distanza $\sigma'$ (e.g., distanza di Levenshtein \cite{binarycodes4correcting}), allora anche le loro foto dovrebbero essere distanti non pi\`{u} di $0.1$, secondo una funzione di distanza $\sigma"$. Comunque, come si pu\`{o} immaginare, le funzioni di somiglianza o di distanza scelte influenzano fortemente le \acrshort{rfds} che sono valide sul database fornito in input. Infatti, una funzione di somiglianza di immagini potrebbe considerare simili due cani solamente perch\'{e} hanno il pelo di un colore simile, il quale non implica che hanno la stessa razza.\par
%Per semplicità, nel resto del testo non verrà esplicitata la funzione di somiglianza o di distanza per gli attributi di tipo stringa, per i quali assumeremo che la funzione utilizzata sia la distanza di Levenshtein.

\section{Algoritmi di ricerca delle RFD}
Come detto in precedenza, le \acrfull{fds} erano originariamente specificate in fase di progettazione come propriet\`{a} di uno schema di un database piuttosto che di una delle sue istanze. Successivamente, con la disponibilit\`{a} di maggiori fonti di dati, hardware con prestazioni migliori e nuove esigenze applicative, sono stati proposti algoritmi per la scoprirle dai dati \cite{efficientdiscoveryfd}. Solo di recente, data la complessit\`{a} del problema, sono stati proposti degli algoritmi per scoprire le \acrfull{rfds} dai dati \cite{rfddiscovery,rfdsurvey,evominingrd,ddiscoveryfromdata,differentialdependencies}. Possiamo catalogare gli algoritmi di scoperta delle \acrfull{fds} in due categorie:
\begin{enumerate}
    \item top-down,
    \item bottom-up.
\end{enumerate}
Gli algoritmi top-down iniziano a generare \acrshort{fds} candidate sulla base di un reticolo di attributi, anche detto \textit{lattice}, che permette di rappresentare tutte le combinazioni di attributi che possono definire \acrshort{fds} candidate, convalidandole, e utilizzano le \acrshort{fds} valide per ridurre lo spazio di ricerca per le \acrshort{fds} candidate ancora da verificare \cite{tanealgfd,fdmine,fun,efficient-fd-discovery}. Mentre, gli algoritmi bottom-up confrontano i valori degli attributi per ciascuna coppia di tuple, al fine di generare due diversi set di dati da cui derivano le \acrshort{fds} candidate \cite{efficientdiscoveryarmstrong,fastfds,dbdependencydiscovery}.\par
In generale, gli algoritmi di ricerca delle \acrshort{fds} hanno ottime performance di spazio e di tempo, mentre l'utilizzo delle funzioni di distanza, delle soglie e delle misure di copertura aumentano considerevolmente la complessit\`{a} degli algoritmi di scoperta delle \acrshort{rfds}. Questo \`{e} uno dei motivi che ha portato all'implementazione di alcuni algoritmi di scoperta di \acrshort{rfds}, nonostante le oltre trenta diverse definizioni di \acrshort{rfd} \cite{rfdsurvey,ddiscoveryfromdata}. Tra questi, troviamo gli approcci per la scoperta di AFD basati sul campionamento \cite{cords,approximateinferencefd}, i quali utilizzano una piccola porzione di tuple $s \subset r$ per decidere se una AFD esiste su $r$. Di conseguenza, le AFD che esistono su $s$ esistono anche su $r$ con una data probabilit\`{a}. Il metodo proposto in \cite{dioscoveryfdindatabase} sfrutta la misura di errore super-keys per determinare soddisfacimento approssimato delle AFD.\par
Per la scoperta delle CFD il problema \`{e} quello di computare le \acrshort{fds} candidate e, per ognuna di esse, scoprire il loro tableau ottimale \cite{generatingtableaux}. Il numero di \acrshort{fds} candidate \`{e} esponenziale. L'algoritmo proposto in \cite{discoveringdataqualityrules} deriva le \acrshort{fds} candidate dal reticolo degli attributi, utilizzando la propriet\`{a} delle partizioni degli attributi. L'algoritmo greedy proposto in \cite{generatingtableaux} calcola un tableau quasi ottimale per una CFD quando viene fornita la \acrshort{fd} candidata. Il supporto e la confidenza sono utilizzati per misurare la vicinanza del tableau scoperto a quello ottimale. In \cite{discoveringconditionalfd} gli autori propongono tre algoritmi, denominati CFD\_Mine, CTANE e FastCFD, i quali sono rispettivamente la controparte di FD\_Mine\cite{fdmine}, TANE\cite{tanealgfd} e FastFD\cite{fastfds}. L'algoritmo CFD\_Mine mira a scoprire le CFD i cui schemi sono privi di wildcard, mentre gli altri due scoprono le CFD generali.\par
Gli algoritmi di scoperta di MD presentati in \cite{efficientdiscoveryofsimilarity} valutano l'utilit\`{a} delle MD su una determinata istanza di database, determinando pattern delle soglie per le MD. L'utilit\`{a} \`{e} misurata attraverso i due parametri di confidenza e di supporto delle MD, mentre le soglie sono determinate in base alla distribuzione dei dati. Vengono introdotte anche delle strategie per filtrare pattern candidati con basso supporto. Inoltre, in \cite{discoveringconditionalmatchingrules} viene discusso nel dettaglio il problema della scoperta delle MD condizionali. In particolare, gli autori definiscono le propriet\`{a} delle CMD e propongono tre algoritmi di scoperta per identificare le CMD con un lato destro specifico [$Y\leftrightharpoons y$]. La scoperta di DD dai dati eredita la complessit\`{a} esponenziale del problema di scoperta di FD. Gli algoritmi di scoperta proposti in \cite{differentialdependencies} sono basati su algoritmi di riduzione: una volta fissata la funzione differenziale del lato destro per ciascun attributo, viene valutato l'insieme delle funzioni differenziali del lato sinistro che formano le DD. Le strategie di pruning proposte per migliorare le performance degli algoritmi di scoperta sono basate sulle propriet\`{a} di assunzione delle funzioni differenziali, sull'implicazione delle DD e sull'esclusione dell'istanza. L'approccio proposto in \cite{miningdd} per la scoperta delle DD riduce lo spazio di ricerca del problema assumendo una soglia di distanza definita dall'utente come limite superiore per gli intervalli di distanza del lato sinistro delle DD. L'algoritmo di scoperta si basa su un modello di clustering basato sulla distanza e include ulteriori strategie di pruning per consentire il rilevamento efficiente di DD per soglie elevate. L'algoritmo proposto in \cite{efficientdiscoverydd} estrae una copertura minima di DD basata su regole di associazione. In particolare, l'approccio applica l'algoritmo presentato in \cite{optimalrulediscovry} per estrarre una classe di regole di associazione non ridondanti, le quali vengono poi trasformate in DD. Quest'ultime subiscono poi dei tagli per generare una cover minimale di DD. Data un'istanza di database ed una DD, l'approccio proposto in \cite{efficientdeterminationofdistance4dd} \`{e} in grado di determinare la soglia di distanza della DD massimizzando la sua utilit\`{a}, misurata in termini di supporto, confidenza e qualit\`{a} dipendente. Gli autori dimostrano inoltre che le soglie di distanza identificate sono effettivamente pi\`{u} efficaci di altre impostazioni selezionate casualmente nell'applicazione del rilevamento delle violazioni.\par
L'approccio introdotto in \cite{rfddiscovery} presenta una tecnica che sfrutta algoritmi basati su reticolo per la scoperta di \acrshort{rfds} rilassate sul confronto dei dati ($RFD_c$) ed un algoritmo per determinare la soglia di distanza pi\`{u} adatta per una determinata $RFD_c$.\par
L'algoritmo genetico introdotto in \cite{evominingrd} mira ad identificare la classe di appartenenza delle \acrshort{rfds} attraverso operazioni ispirate all'evoluzione delle specie naturali, come la selezione naturale, crossover e mutazione. Tramite queste operazioni l'algoritmo genera iterativamente nuove \acrshort{rfds} candidate, poche delle quali sopravvivono al processo di evoluzione. La selezione dei candidati che devono sopravvivere viene effettuata mediante una funzione di fitness, che sfrutta le misure di qualit\`{a} di supporto e confidenza generalmente utilizzate per la valutazione delle regole di associazione.